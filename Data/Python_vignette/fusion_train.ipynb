{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8e8d34-7d2c-4934-8702-ee48db13e971",
   "metadata": {},
   "source": [
    "# Multimodal fusion model training\n",
    "This vignette will demonstrate multimodal fusion classification model training using images DNA metabarcoding data.\n",
    "\n",
    "We recommend running this code on a machine with a GPU and CUDA installed. However, if such a machine is not available to you, the code can be run on a CPU with no issues, but it will be significantly slower.\n",
    "\n",
    "### Files and directory structure\n",
    "\n",
    "Before we begin, it is important that your files are arranged in the correct directory structure. If you cloned our GitHub repository, the files will already be arranged correctly. If you have not cloned the repository, or are applying this vignette to your own data, we have visualized the basic structure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875395e-69b7-4dca-b780-f38e9e1dad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV-eDNA-Hybrid/\n",
    "│── configs/\n",
    "│   │── exp_order_concat.yaml\n",
    "│── Data/\n",
    "│   │── Model_Data/\n",
    "│   │   ├── Images/\n",
    "│   │   │   ├── img01.jpg\n",
    "│   │   │   ├── img02.jpg (etc.)\n",
    "│   │   ├── assemblages/\n",
    "│   │   │   ├── train.csv\n",
    "│   │   │   ├── valid.csv\n",
    "│── Model_Scripts/\n",
    "│   │── tf_loader_concat.py\n",
    "│   │── util_order.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac8b20-b6a4-4bb4-8406-a1179257d1af",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Now that our directory is set up, we can begin with the code. First, we must load the required libraries and modules. We will be using TensorFlow Keras for training. The Anaconda environment used to run this code is specified in the environment.yml file on our GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04640e3-f111-4650-b242-1ca19fc6ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c1f90-5938-439c-ab1a-ab9dc864a4eb",
   "metadata": {},
   "source": [
    "We will also be using some custom modules that must be loaded. The code for these can be found in the \"Model_Scripts\" directory in the GitHub repository. Make sure to set your working directory to the location of \"Model_Scripts\" to ensure the code for this vignette runs correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd81f5-7ab5-45df-b49f-a8bedfd6c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory. Adjust the path to match the location on your machine\n",
    "os.chdir(\"C:/Your/Path/CV-eDNA-Hybrid/Model_Scripts\")\n",
    "\n",
    "from util_order import init_seed\n",
    "from tf_loader_concat import CTDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e6876-f6c1-4d17-92b1-bb5832a0676f",
   "metadata": {},
   "source": [
    "Many of our environment, dataset, and model parameters are defined in a config YAML file. The config files can be found in the \"config\" directory of the GitHub repository. For this code to work properly, you may need to update the `data_root` and `annotate_root` paths to match their corresponding location on your machine. The `data_root` path corresponds to the parent folder where all of your model data is stored (e.g. \"C:/Your/Path/CV-eDNA-Hybrid/Data/Model_Data\"). `annotate_root` should be a subdirectory of `data_root` that contains the train.csv and valid.csv files. These files contain the paths to the corresponding images for each specimen, the specimen's ground truth class, and the specimen's corresponding DNA-based assemblage data.\n",
    "\n",
    "The code below loads the config file and initializes some elements from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3032e9-82c9-4511-8720-50b197eec6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train deep learning model.')\n",
    "parser.add_argument('--config', help='Path to config file', default='../configs/exp_order_fusion.yaml')\n",
    "parser.add_argument('--seed', help='Seed index', type=int, default = 0)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load config\n",
    "print(f'Using config \"{args.config}\"')\n",
    "cfg = yaml.safe_load(open(args.config, 'r'))\n",
    "\n",
    "# Unpacking some stuff from the config\n",
    "cfg[\"seed\"] = cfg[\"seed\"][args.seed]\n",
    "seed = cfg[\"seed\"]\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "ncol = cfg[\"num_col\"]\n",
    "num_class = cfg[\"num_classes\"]\n",
    "experiment = cfg[\"experiment_name\"]\n",
    "\n",
    "# Path to the image annotations\n",
    "anno_path = os.path.join(\n",
    "    cfg[\"data_root\"],\n",
    "    cfg[\"annotate_root\"],\n",
    "    'train.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3826e9e-2619-4387-a58b-71f109b83b15",
   "metadata": {},
   "source": [
    "Our dataset is imbalanced, as some classes are more abundant than others. To account for this, we compute class weights which are later used to adjust the loss function during the training step. This should not be confused with the \"weighted masks\" discussed in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695ab3e-a4eb-4d5f-9ed3-6748c742af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the annotations and setting class weights\n",
    "meta = pd.read_csv(anno_path)\n",
    "classes = meta[\"longlab\"].values\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(classes), y=classes)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d132208-6597-43bc-95c7-bb886a9d7363",
   "metadata": {},
   "source": [
    "Next we initialize our training and validation data loaders, which pair images with their corresponding DNA-based assemblage data and ground truth class names. The full code for the data loader can be found in the tf_loader_concat.py file in the Model_Scipts folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec915742-0819-4b86-a38f-95d7a7b19500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "init_seed(seed)\n",
    "\n",
    "# Initialize the datasets\n",
    "train_loader = CTDataset(cfg, split='train')\n",
    "valid_loader = CTDataset(cfg, split='valid')\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_data = train_loader.create_tf_dataset()\n",
    "valid_data = valid_loader.create_tf_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddde1b6-8e34-46f7-82ad-07bf51723b7c",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "Now that we have completed our setup, we are ready to define our model architecture. First, we define a shallow neural network that the assemblage data will pass through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b638281-d870-45d0-a6f4-6a78e831ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple ANN for tabular data\n",
    "inputs = Input(shape = (ncol,))\n",
    "annx = Dense(128)(inputs)\n",
    "annx = BatchNormalization()(annx)\n",
    "annx = Activation('relu')(annx)\n",
    "annx = Dropout(0.3)(annx)\n",
    "ann = Model(inputs, annx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864a7de-a5c5-40bb-b0ed-f4b61c8616ad",
   "metadata": {},
   "source": [
    "Next, we define our CNN architecture. We will be using the ResNet-50 architecture with preloaded ImageNet weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef02f43-9d10-4ab8-955a-6b80920e42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet for image data\n",
    "base_model = ResNet50(include_top = False, weights = 'imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "resnet = Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86d487-b0a5-4f90-8a2e-9d86fa19f9ec",
   "metadata": {},
   "source": [
    "Next, we concantenate the outputs of the shallow neural network (`ann`) and the CNN (`resnet`). The concatenated layer is then passed through another shallow neural network before reaching the classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd2cc6-7de8-459f-b02f-aaf1895697dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the ANN output with the ResNet output\n",
    "concat = concatenate([ann.output, resnet.output])\n",
    "\n",
    "# Inputting the concatenated layer to another ANN for final classification\n",
    "combined = Dense(128)(concat)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('relu')(combined)\n",
    "combined = Dropout(0.3)(combined)\n",
    "combined = Dense(num_class, activation = \"softmax\")(combined)\n",
    "model = Model(inputs = [ann.input, resnet.input], outputs = combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f2ac8-1bf1-436d-92eb-3c534a2335ed",
   "metadata": {},
   "source": [
    "### Model parameters and training\n",
    "\n",
    "Now that we've defined the model archtecture, we only need to set a few more parameters before training the model. Here, we set the learning rate, optimizer, and number of epochs. We also create a model checkpoint that saves the model whenever an epoch produces a new best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad37166-bb83-43b0-9e8a-186d8cc54549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "learning_rate = cfg['learning_rate']\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "epochs = 150\n",
    "\n",
    "cp_loss = ModelCheckpoint(f'{experiment}_loss.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48dc3c4-8e82-4f98-bc4f-80ead4510f3e",
   "metadata": {},
   "source": [
    "Finally, we compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb5bd8-ad57-41b6-93e0-d06793c0a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Model fitting\n",
    "history = model.fit(train_data,\n",
    "                    epochs = epochs, \n",
    "                    verbose = 1,\n",
    "                    validation_data = valid_data,\n",
    "                    callbacks = [cp_loss,\n",
    "                                 cp_acc],\n",
    "                    class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258113af-9f20-4533-9e98-eb03aeaea5bc",
   "metadata": {},
   "source": [
    "The model can be evaluated the same as any other TensorFlow Keras model. To see how we evaluated our model, refer to order_concat_eval.py in Model_Scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
